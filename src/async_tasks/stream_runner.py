# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

import asyncio
import logging
from typing import Dict, List, Any, Optional, Callable, cast
from langchain_core.messages import AIMessageChunk, ToolMessage, BaseMessage
from langgraph.types import Command

from src.config.redis_config import write_event_to_stream
from src.graph.builder import build_graph_with_memory
from src.rag.retriever import Resource
from src.config.report_style import ReportStyle
from .task_manager import TaskManager, TaskStatus

logger = logging.getLogger(__name__)


def should_save_tool_call_chunk(chunk) -> bool:
    """
    åˆ¤æ–­tool_call_chunkæ˜¯å¦åº”è¯¥ä¿å­˜
    è¿‡æ»¤æ‰æ— æ•ˆçš„chunkï¼ˆä¾‹å¦‚nameä¸ºNoneçš„chunkï¼‰
    """
    if chunk is None:
        return False
    
    # å¦‚æœchunkæœ‰nameå­—æ®µï¼Œå¿…é¡»ä¸ä¸ºNone
    if hasattr(chunk, 'name') and chunk.name is None:
        return False
    
    # å¦‚æœchunkæœ‰argså­—æ®µï¼Œå¿…é¡»ä¸ä¸ºç©º
    if hasattr(chunk, 'args') and (chunk.args is None or chunk.args == ''):
        return False
    
    return True


class StreamGraphRunner:
    """æµå¼å›¾æ‰§è¡Œå™¨ - è´Ÿè´£å¼‚æ­¥æ‰§è¡Œ LangGraph å¹¶å†™å…¥ Redis Stream"""
    
    def __init__(self, task_manager: Optional[TaskManager] = None):
        self.graph = build_graph_with_memory()
        self.task_manager = task_manager or TaskManager()
        
    async def execute_async(
        self,
        task_id: str,
        messages: List[dict],
        thread_id: str,
        resources: List[Resource] = None,
        max_plan_iterations: int = 1,
        max_step_num: int = 3,
        max_search_results: int = 3,
        auto_accepted_plan: bool = True,
        interrupt_feedback: str = None,
        mcp_settings: dict = None,
        enable_background_investigation: bool = True,
        report_style = ReportStyle.ACADEMIC,
        enable_deep_thinking: bool = False,
        progress_callback: Optional[Callable[[float, str], None]] = None
    ) -> dict:
        """
        å¼‚æ­¥æ‰§è¡Œå·¥ä½œæµå¹¶å°†äº‹ä»¶å†™å…¥ Redis Stream
        
        Args:
            task_id: ä»»åŠ¡ID
            messages: æ¶ˆæ¯åˆ—è¡¨
            thread_id: çº¿ç¨‹ID
            å…¶ä»–å‚æ•°: å·¥ä½œæµé…ç½®å‚æ•°
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            dict: æ‰§è¡Œç»“æœ
        """
        try:
            # ä½¿ç”¨ task_id ä½œä¸º query_idï¼Œä¸å›æ”¾ API ä¿æŒä¸€è‡´
            query_id = task_id
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
            self.task_manager.update_task_status(
                task_id, 
                TaskStatus.RUNNING, 
                current_step="åˆå§‹åŒ–å·¥ä½œæµ"
            )
            
            # å†™å…¥ç ”ç©¶å¼€å§‹äº‹ä»¶
            try:
                research_id = query_id
                start_event_payload = {
                    "task_id": task_id,
                    "thread_id": thread_id,
                    "query_id": query_id,
                    "research_id": research_id,
                    "id": research_id,
                    "role": "assistant",
                    "agent": "researcher",
                    "content": "å¼€å§‹ç ”ç©¶è°ƒæŸ¥...",
                    "status": "running",
                    "topic": messages[-1]["content"] if messages else "",
                    "research_topic": messages[-1]["content"] if messages else "",
                }
                write_event_to_stream(thread_id, "research_start", start_event_payload, task_id)
                logger.info(f"âœ… å†™å…¥research_startäº‹ä»¶: {thread_id}:{task_id}")
            except Exception as e:
                logger.error(f"âŒ å†™å…¥research_startäº‹ä»¶å¤±è´¥: {e}")
            
            # æ„å»ºè¾“å…¥æ•°æ®
            input_data = {
                "messages": messages,
                "plan_iterations": 0,
                "final_report": "",
                "current_plan": None,
                "observations": [],
                "auto_accepted_plan": auto_accepted_plan,
                "enable_background_investigation": enable_background_investigation,
                "research_topic": messages[-1]["content"] if messages else "",
            }
            
            # å¤„ç†ä¸­æ–­åé¦ˆ
            if not auto_accepted_plan and interrupt_feedback:
                resume_msg = f"[{interrupt_feedback}]"
                if messages:
                    resume_msg += f" {messages[-1]['content']}"
                input_data = Command(resume=resume_msg)
            
            # æ„å»ºé…ç½® - ä¸åŸå§‹chat_streamä¿æŒä¸€è‡´
            config = {
                "thread_id": thread_id,
                "resources": resources or [],
                "max_plan_iterations": max_plan_iterations,
                "max_step_num": max_step_num,
                "max_search_results": max_search_results,
                "mcp_settings": mcp_settings or {},
                "report_style": report_style.value if hasattr(report_style, 'value') else str(report_style),
                "enable_deep_thinking": enable_deep_thinking,
            }
            
            logger.info(f"ğŸš€ å¼€å§‹å¼‚æ­¥æ‰§è¡Œå·¥ä½œæµ: task_id={task_id}, thread_id={thread_id}")
            
            # æ‰§è¡Œå›¾å¹¶å¤„ç†äº‹ä»¶æµ - å®Œå…¨å¤åˆ¶åŸæœ‰çš„_astream_workflow_generatoré€»è¾‘
            event_count = 0
            final_result = None
            
            async for agent, _, event_data in self.graph.astream(
                input_data,
                config=config,
                stream_mode=["messages", "updates"],
                subgraphs=True,
            ):
                event_count += 1
                logger.debug(f"ğŸ“¨ æ”¶åˆ°äº‹ä»¶ #{event_count}: agent={agent}, type={type(event_data)}")
                
                # å¤„ç†å­—å…¸ç±»å‹äº‹ä»¶ï¼ˆä¸­æ–­äº‹ä»¶ï¼‰
                if isinstance(event_data, dict):
                    if "__interrupt__" in event_data:
                        await self._handle_interrupt_event(task_id, thread_id, event_data, query_id)
                    continue
                
                # å¤„ç†æ¶ˆæ¯äº‹ä»¶ - å®Œå…¨æŒ‰ç…§åŸæœ‰é€»è¾‘å¤„ç†
                message_chunk, message_metadata = cast(
                    tuple[BaseMessage, dict[str, any]], event_data
                )
                
                # æ„å»ºåŸºç¡€äº‹ä»¶æ¶ˆæ¯
                event_stream_message: dict[str, any] = {
                    "thread_id": thread_id,
                    "query_id": query_id,
                    "agent": agent[0].split(":")[0],
                    "id": message_chunk.id,
                    "role": "assistant",
                    "content": message_chunk.content,
                }
                
                # æ·»åŠ æ¨ç†å†…å®¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if message_chunk.additional_kwargs.get("reasoning_content"):
                    event_stream_message["reasoning_content"] = message_chunk.additional_kwargs[
                        "reasoning_content"
                    ]
                
                # æ·»åŠ å®ŒæˆåŸå› ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if message_chunk.response_metadata.get("finish_reason"):
                    event_stream_message["finish_reason"] = message_chunk.response_metadata.get(
                        "finish_reason"
                    )
                
                # æ ¹æ®æ¶ˆæ¯ç±»å‹å¤„ç†ä¸åŒçš„äº‹ä»¶
                if isinstance(message_chunk, ToolMessage):
                    # Tool Message - å·¥å…·è°ƒç”¨ç»“æœ
                    event_stream_message["tool_call_id"] = message_chunk.tool_call_id
                    await self._write_event_to_redis("tool_call_result", event_stream_message, thread_id, task_id)
                    
                elif isinstance(message_chunk, AIMessageChunk):
                    # AI Message Chunk - æ ¹æ®å†…å®¹ç±»å‹åˆ†ç±»å¤„ç†
                    if message_chunk.tool_calls:
                        # AI Message - å·¥å…·è°ƒç”¨
                        event_stream_message["tool_calls"] = message_chunk.tool_calls
                        event_stream_message["tool_call_chunks"] = (
                            message_chunk.tool_call_chunks
                        )
                        await self._write_event_to_redis("tool_calls", event_stream_message, thread_id, task_id)
                        
                    elif message_chunk.tool_call_chunks:
                        # AI Message - å·¥å…·è°ƒç”¨åˆ†å—
                        # è¿‡æ»¤æ‰æ— æ•ˆçš„tool_call_chunks
                        valid_chunks = []
                        for chunk in message_chunk.tool_call_chunks:
                            if should_save_tool_call_chunk(chunk):
                                valid_chunks.append(chunk)
                        
                        # åªæœ‰å­˜åœ¨æœ‰æ•ˆchunksæ—¶æ‰ä¿å­˜å’Œå‘é€
                        if valid_chunks:
                            event_stream_message["tool_call_chunks"] = valid_chunks
                            await self._write_event_to_redis("tool_call_chunks", event_stream_message, thread_id, task_id)
                    else:
                        # AI Message - æ™®é€šæ¶ˆæ¯åˆ†å—
                        await self._write_event_to_redis("message_chunk", event_stream_message, thread_id, task_id)
                
                # æ›´æ–°è¿›åº¦ï¼ˆæ¯50ä¸ªäº‹ä»¶æ›´æ–°ä¸€æ¬¡ï¼‰
                if event_count % 50 == 0:
                    progress = min(0.9, event_count / 1000.0)  # æœ€å¤§90%ï¼Œç•™10%ç»™å®ŒæˆçŠ¶æ€
                    self.task_manager.update_task_status(
                        task_id,
                        TaskStatus.RUNNING,
                        progress=progress,
                        current_step=f"å¤„ç†äº‹ä»¶ä¸­... ({event_count} ä¸ªäº‹ä»¶)"
                    )
                    if progress_callback:
                        progress_callback(progress, f"å¤„ç†äº‹ä»¶ä¸­... ({event_count} ä¸ªäº‹ä»¶)")
            
            # å†™å…¥ç ”ç©¶ç»“æŸäº‹ä»¶
            try:
                research_id = query_id
                end_event_payload = {
                    "thread_id": thread_id,
                    "query_id": query_id,
                    "research_id": research_id,
                    "id": research_id,
                    "role": "assistant",
                    "agent": "reporter",
                    "content": "ç ”ç©¶è°ƒæŸ¥å®Œæˆ",
                    "status": "completed",
                    "finish_reason": "completed",
                }
                write_event_to_stream(thread_id, "research_end", end_event_payload, task_id)
                logger.info(f"âœ… å†™å…¥research_endäº‹ä»¶: {thread_id}:{task_id}")
            except Exception as e:
                logger.error(f"âŒ å†™å…¥research_endäº‹ä»¶å¤±è´¥: {e}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
            self.task_manager.update_task_status(
                task_id,
                TaskStatus.COMPLETED,
                progress=1.0,
                current_step=f"ä»»åŠ¡å®Œæˆï¼Œå…±å¤„ç† {event_count} ä¸ªäº‹ä»¶"
            )
            
            logger.info(f"âœ… å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œå®Œæˆ: task_id={task_id}, äº‹ä»¶æ€»æ•°={event_count}")
            
            return {
                "task_id": task_id,
                "status": "completed",
                "event_count": event_count,
                "final_result": final_result
            }
            
        except Exception as e:
            logger.error(f"âŒ å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥: task_id={task_id}, é”™è¯¯: {e}", exc_info=True)
            
            # å†™å…¥é”™è¯¯äº‹ä»¶
            try:
                await self._write_error_event(task_id, thread_id, str(e), task_id)
            except Exception as error_write_error:
                logger.error(f"âŒ å†™å…¥é”™è¯¯äº‹ä»¶å¤±è´¥: {error_write_error}")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
            self.task_manager.update_task_status(
                task_id,
                TaskStatus.FAILED,
                error_message=str(e)
            )
            
            raise
    
    async def _write_event_to_redis(self, event_type: str, event_data: dict, thread_id: str, task_id: str):
        """å†™å…¥äº‹ä»¶åˆ°Redis Streamï¼Œå¹¶æ·»åŠ é”™è¯¯å¤„ç†"""
        try:
            write_event_to_stream(thread_id, event_type, event_data, task_id)
            logger.debug(f"âœ… å†™å…¥{event_type}äº‹ä»¶: {thread_id}:{task_id}")
        except Exception as e:
            logger.error(f"âŒ å†™å…¥{event_type}äº‹ä»¶å¤±è´¥: {e}")
    
    async def _handle_interrupt_event(self, task_id: str, thread_id: str, event_data: dict, query_id: str):
        """å¤„ç†ä¸­æ–­äº‹ä»¶"""
        try:
            event_payload = {
                "task_id": task_id,
                "thread_id": thread_id,
                "query_id": query_id,
                "id": event_data["__interrupt__"][0].ns[0],
                "role": "assistant",
                "content": event_data["__interrupt__"][0].value,
                "finish_reason": "interrupt",
                "options": [
                    {"text": "Edit plan", "value": "edit_plan"},
                    {"text": "Start research", "value": "accepted"},
                ],
            }
            await self._write_event_to_redis("interrupt", event_payload, thread_id, task_id)
            logger.info(f"âœ… å¤„ç†ä¸­æ–­äº‹ä»¶: {thread_id}:{task_id}")
        except Exception as e:
            logger.error(f"âŒ å¤„ç†ä¸­æ–­äº‹ä»¶å¤±è´¥: {e}")
    
    async def _write_error_event(self, task_id: str, thread_id: str, error_message: str, query_id: str):
        """å†™å…¥é”™è¯¯äº‹ä»¶"""
        try:
            error_payload = {
                "task_id": task_id,
                "thread_id": thread_id,
                "query_id": query_id,
                "id": f"error_{task_id}",
                "role": "assistant",
                "agent": "system",
                "content": error_message,
                "message": error_message,
                "finish_reason": "error",
            }
            write_event_to_stream(thread_id, "error", error_payload, task_id)
            logger.info(f"âœ… å†™å…¥é”™è¯¯äº‹ä»¶: {thread_id}:{task_id}")
        except Exception as e:
            logger.error(f"âŒ å†™å…¥é”™è¯¯äº‹ä»¶å¤±è´¥: {e}")
    
    def stop_task(self, task_id: str) -> bool:
        """åœæ­¢ä»»åŠ¡ï¼ˆæš‚æœªå®ç°ï¼‰"""
        logger.warning(f"åœæ­¢ä»»åŠ¡åŠŸèƒ½æš‚æœªå®ç°: {task_id}")
        return False 