# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

import asyncio
import base64
import json
import logging
import os
from typing import Annotated, List, Optional, cast
from uuid import uuid4

from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import Response, StreamingResponse
from langchain_core.messages import AIMessageChunk, ToolMessage, BaseMessage
from langgraph.types import Command

from src.config.redis_config import write_event_to_stream, read_events_from_stream, get_redis_client

from src.config.report_style import ReportStyle
from src.config.tools import SELECTED_RAG_PROVIDER
from src.graph.builder import build_graph_with_memory
from src.podcast.graph.builder import build_graph as build_podcast_graph
from src.ppt.graph.builder import build_graph as build_ppt_graph
from src.prose.graph.builder import build_graph as build_prose_graph
from src.prompt_enhancer.graph.builder import build_graph as build_prompt_enhancer_graph
from src.rag.builder import build_retriever
from src.rag.retriever import Resource
from src.server.chat_request import (
    ChatRequest,
    EnhancePromptRequest,
    GeneratePodcastRequest,
    GeneratePPTRequest,
    GenerateProseRequest,
    TTSRequest,
)
from src.server.mcp_request import MCPServerMetadataRequest, MCPServerMetadataResponse
from src.server.mcp_utils import load_mcp_tools
from src.server.rag_request import (
    RAGConfigResponse,
    RAGResourceRequest,
    RAGResourcesResponse,
)
from src.server.config_request import ConfigResponse
from src.server.async_request import (
    AsyncTaskRequest,
    AsyncTaskResponse, 
    TaskStatusResponse,
    TaskListResponse,
    WorkerStatsResponse,
    TaskCancelResponse,
)
from src.llms.llm import get_configured_llm_models
from src.tools import VolcengineTTS
from src.async_tasks import TaskManager
from src.async_tasks.task_manager import TaskStatus

logger = logging.getLogger(__name__)

INTERNAL_SERVER_ERROR_DETAIL = "Internal Server Error"

app = FastAPI(
    title="DeerFlow API",
    description="API for Deer",
    version="0.1.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allows all origins
    allow_credentials=True,
    allow_methods=["*"],  # Allows all methods
    allow_headers=["*"],  # Allows all headers
)

graph = build_graph_with_memory()

# åˆå§‹åŒ–å¼‚æ­¥ä»»åŠ¡ç›¸å…³ç»„ä»¶
task_manager = TaskManager()


@app.post("/api/chat/stream")
async def chat_stream(request: ChatRequest):
    thread_id = request.thread_id
    if thread_id == "__default__":
        thread_id = str(uuid4())
    return StreamingResponse(
        _astream_workflow_generator(
            request.model_dump()["messages"],
            thread_id,
            request.resources,
            request.max_plan_iterations,
            request.max_step_num,
            request.max_search_results,
            request.auto_accepted_plan,
            request.interrupt_feedback,
            request.mcp_settings,
            request.enable_background_investigation,
            request.report_style,
            request.enable_deep_thinking,
        ),
        media_type="text/event-stream",
    )


async def _astream_workflow_generator(
    messages: List[dict],
    thread_id: str,
    resources: List[Resource],
    max_plan_iterations: int,
    max_step_num: int,
    max_search_results: int,
    auto_accepted_plan: bool,
    interrupt_feedback: str,
    mcp_settings: dict,
    enable_background_investigation: bool,
    report_style: ReportStyle,
    enable_deep_thinking: bool,
):
    # ç”ŸæˆæŸ¥è¯¢IDä½œä¸ºstream suffix
    query_id = str(uuid4())
    
    input_ = {
        "messages": messages,
        "plan_iterations": 0,
        "final_report": "",
        "current_plan": None,
        "observations": [],
        "auto_accepted_plan": auto_accepted_plan,
        "enable_background_investigation": enable_background_investigation,
        "research_topic": messages[-1]["content"] if messages else "",
    }
    if not auto_accepted_plan and interrupt_feedback:
        resume_msg = f"[{interrupt_feedback}]"
        # add the last message to the resume message
        if messages:
            resume_msg += f" {messages[-1]['content']}"
        input_ = Command(resume=resume_msg)
    
    # å†™å…¥ç ”ç©¶å¼€å§‹äº‹ä»¶
    try:
        # ä½¿ç”¨query_idä½œä¸ºresearch_idï¼Œç¡®ä¿å‰ç«¯èƒ½æ­£ç¡®è¯†åˆ«æ­£åœ¨è¿›è¡Œçš„ç ”ç©¶
        research_id = query_id
        start_event_payload = {
            "thread_id": thread_id,
            "query_id": query_id,
            "research_id": research_id,  # æ·»åŠ research_idå­—æ®µ
            "id": research_id,  # æ·»åŠ idå­—æ®µç”¨äºæ¶ˆæ¯è¯†åˆ«
            "role": "assistant",
            "agent": "researcher",  # æ·»åŠ agentå­—æ®µ
            "content": "å¼€å§‹ç ”ç©¶è°ƒæŸ¥...",
            "status": "running",  # æ”¹ä¸ºrunningçŠ¶æ€
            "topic": messages[-1]["content"] if messages else "",  # é‡å‘½åä¸ºtopic
            "research_topic": messages[-1]["content"] if messages else "",
        }
        write_event_to_stream(thread_id, "research_start", start_event_payload, query_id)
        logger.debug(f"æˆåŠŸå†™å…¥research_startäº‹ä»¶åˆ°Redis Stream: {thread_id}:{query_id}, research_id: {research_id}")
    except Exception as e:
        logger.error(f"å†™å…¥research_startäº‹ä»¶åˆ°Redis Streamå¤±è´¥: {e}")
    
    async for agent, _, event_data in graph.astream(
        input_,
        config={
            "thread_id": thread_id,
            "resources": resources,
            "max_plan_iterations": max_plan_iterations,
            "max_step_num": max_step_num,
            "max_search_results": max_search_results,
            "mcp_settings": mcp_settings,
            "report_style": report_style.value,
            "enable_deep_thinking": enable_deep_thinking,
        },
        stream_mode=["messages", "updates"],
        subgraphs=True,
    ):
        if isinstance(event_data, dict):
            if "__interrupt__" in event_data:
                event_payload = {
                    "thread_id": thread_id,
                    "query_id": query_id,
                    "id": event_data["__interrupt__"][0].ns[0],
                    "role": "assistant",
                    "content": event_data["__interrupt__"][0].value,
                    "finish_reason": "interrupt",
                    "options": [
                        {"text": "Edit plan", "value": "edit_plan"},
                        {"text": "Start research", "value": "accepted"},
                    ],
                }
                # å†™å…¥Redis Stream
                try:
                    write_event_to_stream(thread_id, "interrupt", event_payload, query_id)
                    logger.debug(f"æˆåŠŸå†™å…¥interruptäº‹ä»¶åˆ°Redis Stream: {thread_id}:{query_id}")
                except Exception as e:
                    logger.error(f"å†™å…¥interruptäº‹ä»¶åˆ°Redis Streamå¤±è´¥: {e}")
                
                yield _make_event("interrupt", event_payload)
            continue
        message_chunk, message_metadata = cast(
            tuple[BaseMessage, dict[str, any]], event_data
        )
        event_stream_message: dict[str, any] = {
            "thread_id": thread_id,
            "query_id": query_id,
            "agent": agent[0].split(":")[0],
            "id": message_chunk.id,
            "role": "assistant",
            "content": message_chunk.content,
        }
        if message_chunk.additional_kwargs.get("reasoning_content"):
            event_stream_message["reasoning_content"] = message_chunk.additional_kwargs[
                "reasoning_content"
            ]
        if message_chunk.response_metadata.get("finish_reason"):
            event_stream_message["finish_reason"] = message_chunk.response_metadata.get(
                "finish_reason"
            )
        if isinstance(message_chunk, ToolMessage):
            # Tool Message - Return the result of the tool call
            event_stream_message["tool_call_id"] = message_chunk.tool_call_id
            
            # å†™å…¥Redis Stream
            try:
                write_event_to_stream(thread_id, "tool_call_result", event_stream_message, query_id)
                logger.debug(f"æˆåŠŸå†™å…¥tool_call_resultäº‹ä»¶åˆ°Redis Stream: {thread_id}:{query_id}")
            except Exception as e:
                logger.error(f"å†™å…¥tool_call_resultäº‹ä»¶åˆ°Redis Streamå¤±è´¥: {e}")
            
            yield _make_event("tool_call_result", event_stream_message)
        elif isinstance(message_chunk, AIMessageChunk):
            # AI Message - Raw message tokens
            if message_chunk.tool_calls:
                # AI Message - Tool Call
                event_stream_message["tool_calls"] = message_chunk.tool_calls
                event_stream_message["tool_call_chunks"] = (
                    message_chunk.tool_call_chunks
                )
                
                # å†™å…¥Redis Stream
                try:
                    write_event_to_stream(thread_id, "tool_calls", event_stream_message, query_id)
                    logger.debug(f"æˆåŠŸå†™å…¥tool_callsäº‹ä»¶åˆ°Redis Stream: {thread_id}:{query_id}")
                except Exception as e:
                    logger.error(f"å†™å…¥tool_callsäº‹ä»¶åˆ°Redis Streamå¤±è´¥: {e}")
                
                yield _make_event("tool_calls", event_stream_message)
            elif message_chunk.tool_call_chunks:
                # AI Message - Tool Call Chunks
                # è¿‡æ»¤æ‰æ— æ•ˆçš„tool_call_chunks
                valid_chunks = []
                for chunk in message_chunk.tool_call_chunks:
                    # è¿‡æ»¤æ‰æ— æ•ˆçš„chunk
                    if should_save_tool_call_chunk(chunk):
                        valid_chunks.append(chunk)
                
                # åªæœ‰å­˜åœ¨æœ‰æ•ˆchunksæ—¶æ‰ä¿å­˜å’Œå‘é€
                if valid_chunks:
                    event_stream_message["tool_call_chunks"] = valid_chunks
                
                # å†™å…¥Redis Stream
                try:
                    write_event_to_stream(thread_id, "tool_call_chunks", event_stream_message, query_id)
                    logger.debug(f"æˆåŠŸå†™å…¥tool_call_chunksäº‹ä»¶åˆ°Redis Stream: {thread_id}:{query_id}, æœ‰æ•ˆchunks: {len(valid_chunks)}")
                except Exception as e:
                    logger.error(f"å†™å…¥tool_call_chunksäº‹ä»¶åˆ°Redis Streamå¤±è´¥: {e}")
                
                yield _make_event("tool_call_chunks", event_stream_message)
            else:
                # AI Message - Raw message tokens
                
                # å†™å…¥Redis Stream
                try:
                    write_event_to_stream(thread_id, "message_chunk", event_stream_message, query_id)
                    logger.debug(f"æˆåŠŸå†™å…¥message_chunkäº‹ä»¶åˆ°Redis Stream: {thread_id}:{query_id}")
                except Exception as e:
                    logger.error(f"å†™å…¥message_chunkäº‹ä»¶åˆ°Redis Streamå¤±è´¥: {e}")
                
                yield _make_event("message_chunk", event_stream_message)
    
    # å†™å…¥ç ”ç©¶ç»“æŸäº‹ä»¶
    try:
        research_id = query_id
        end_event_payload = {
            "thread_id": thread_id,
            "query_id": query_id,
            "research_id": research_id,  # æ·»åŠ research_idå­—æ®µ
            "id": research_id,  # æ·»åŠ idå­—æ®µç”¨äºæ¶ˆæ¯è¯†åˆ«
            "role": "assistant",
            "agent": "reporter",  # æ·»åŠ agentå­—æ®µ
            "content": "ç ”ç©¶è°ƒæŸ¥å®Œæˆ",
            "status": "completed",
            "finish_reason": "completed",
        }
        write_event_to_stream(thread_id, "research_end", end_event_payload, query_id)
        logger.debug(f"æˆåŠŸå†™å…¥research_endäº‹ä»¶åˆ°Redis Stream: {thread_id}:{query_id}, research_id: {research_id}")
    except Exception as e:
        logger.error(f"å†™å…¥research_endäº‹ä»¶åˆ°Redis Streamå¤±è´¥: {e}")


def _make_event(event_type: str, data: dict[str, any]):
    if data.get("content") == "":
        data.pop("content")
    return f"event: {event_type}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"


@app.post("/api/tts")
async def text_to_speech(request: TTSRequest):
    """Convert text to speech using volcengine TTS API."""
    try:
        app_id = os.getenv("VOLCENGINE_TTS_APPID", "")
        if not app_id:
            raise HTTPException(
                status_code=400, detail="VOLCENGINE_TTS_APPID is not set"
            )
        access_token = os.getenv("VOLCENGINE_TTS_ACCESS_TOKEN", "")
        if not access_token:
            raise HTTPException(
                status_code=400, detail="VOLCENGINE_TTS_ACCESS_TOKEN is not set"
            )
        cluster = os.getenv("VOLCENGINE_TTS_CLUSTER", "volcano_tts")
        voice_type = os.getenv("VOLCENGINE_TTS_VOICE_TYPE", "BV700_V2_streaming")

        tts_client = VolcengineTTS(
            appid=app_id,
            access_token=access_token,
            cluster=cluster,
            voice_type=voice_type,
        )
        # Call the TTS API
        result = tts_client.text_to_speech(
            text=request.text[:1024],
            encoding=request.encoding,
            speed_ratio=request.speed_ratio,
            volume_ratio=request.volume_ratio,
            pitch_ratio=request.pitch_ratio,
            text_type=request.text_type,
            with_frontend=request.with_frontend,
            frontend_type=request.frontend_type,
        )

        if not result["success"]:
            raise HTTPException(status_code=500, detail=str(result["error"]))

        # Decode the base64 audio data
        audio_data = base64.b64decode(result["audio_data"])

        # Return the audio file
        return Response(
            content=audio_data,
            media_type=f"audio/{request.encoding}",
            headers={
                "Content-Disposition": (
                    f"attachment; filename=tts_output.{request.encoding}"
                )
            },
        )
    except Exception as e:
        logger.exception(f"Error in TTS endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=INTERNAL_SERVER_ERROR_DETAIL)


@app.post("/api/podcast/generate")
async def generate_podcast(request: GeneratePodcastRequest):
    try:
        report_content = request.content
        print(report_content)
        workflow = build_podcast_graph()
        final_state = workflow.invoke({"input": report_content})
        audio_bytes = final_state["output"]
        return Response(content=audio_bytes, media_type="audio/mp3")
    except Exception as e:
        logger.exception(f"Error occurred during podcast generation: {str(e)}")
        raise HTTPException(status_code=500, detail=INTERNAL_SERVER_ERROR_DETAIL)


@app.post("/api/ppt/generate")
async def generate_ppt(request: GeneratePPTRequest):
    try:
        report_content = request.content
        print(report_content)
        workflow = build_ppt_graph()
        final_state = workflow.invoke({"input": report_content})
        generated_file_path = final_state["generated_file_path"]
        with open(generated_file_path, "rb") as f:
            ppt_bytes = f.read()
        return Response(
            content=ppt_bytes,
            media_type="application/vnd.openxmlformats-officedocument.presentationml.presentation",
        )
    except Exception as e:
        logger.exception(f"Error occurred during ppt generation: {str(e)}")
        raise HTTPException(status_code=500, detail=INTERNAL_SERVER_ERROR_DETAIL)


@app.post("/api/prose/generate")
async def generate_prose(request: GenerateProseRequest):
    try:
        sanitized_prompt = request.prompt.replace("\r\n", "").replace("\n", "")
        logger.info(f"Generating prose for prompt: {sanitized_prompt}")
        workflow = build_prose_graph()
        events = workflow.astream(
            {
                "content": request.prompt,
                "option": request.option,
                "command": request.command,
            },
            stream_mode="messages",
            subgraphs=True,
        )
        return StreamingResponse(
            (f"data: {event[0].content}\n\n" async for _, event in events),
            media_type="text/event-stream",
        )
    except Exception as e:
        logger.exception(f"Error occurred during prose generation: {str(e)}")
        raise HTTPException(status_code=500, detail=INTERNAL_SERVER_ERROR_DETAIL)


@app.post("/api/prompt/enhance")
async def enhance_prompt(request: EnhancePromptRequest):
    try:
        sanitized_prompt = request.prompt.replace("\r\n", "").replace("\n", "")
        logger.info(f"Enhancing prompt: {sanitized_prompt}")

        # Convert string report_style to ReportStyle enum
        report_style = None
        if request.report_style:
            try:
                # Handle both uppercase and lowercase input
                style_mapping = {
                    "ACADEMIC": ReportStyle.ACADEMIC,
                    "POPULAR_SCIENCE": ReportStyle.POPULAR_SCIENCE,
                    "NEWS": ReportStyle.NEWS,
                    "SOCIAL_MEDIA": ReportStyle.SOCIAL_MEDIA,
                    "academic": ReportStyle.ACADEMIC,
                    "popular_science": ReportStyle.POPULAR_SCIENCE,
                    "news": ReportStyle.NEWS,
                    "social_media": ReportStyle.SOCIAL_MEDIA,
                }
                report_style = style_mapping.get(
                    request.report_style, ReportStyle.ACADEMIC
                )
            except Exception:
                # If invalid style, default to ACADEMIC
                report_style = ReportStyle.ACADEMIC
        else:
            report_style = ReportStyle.ACADEMIC

        workflow = build_prompt_enhancer_graph()
        final_state = workflow.invoke(
            {
                "prompt": request.prompt,
                "context": request.context,
                "report_style": report_style,
            }
        )
        return {"result": final_state["output"]}
    except Exception as e:
        logger.exception(f"Error occurred during prompt enhancement: {str(e)}")
        raise HTTPException(status_code=500, detail=INTERNAL_SERVER_ERROR_DETAIL)


@app.post("/api/mcp/server/metadata", response_model=MCPServerMetadataResponse)
async def mcp_server_metadata(request: MCPServerMetadataRequest):
    """Get information about an MCP server."""
    try:
        # Set default timeout with a longer value for this endpoint
        timeout = 300  # Default to 300 seconds for this endpoint

        # Use custom timeout from request if provided
        if request.timeout_seconds is not None:
            timeout = request.timeout_seconds

        # Load tools from the MCP server using the utility function
        tools = await load_mcp_tools(
            server_type=request.transport,
            command=request.command,
            args=request.args,
            url=request.url,
            env=request.env,
            timeout_seconds=timeout,
        )

        # Create the response with tools
        response = MCPServerMetadataResponse(
            transport=request.transport,
            command=request.command,
            args=request.args,
            url=request.url,
            env=request.env,
            tools=tools,
        )

        return response
    except Exception as e:
        if not isinstance(e, HTTPException):
            logger.exception(f"Error in MCP server metadata endpoint: {str(e)}")
            raise HTTPException(status_code=500, detail=INTERNAL_SERVER_ERROR_DETAIL)
        raise


@app.get("/api/rag/config", response_model=RAGConfigResponse)
async def rag_config():
    """Get the config of the RAG."""
    return RAGConfigResponse(provider=SELECTED_RAG_PROVIDER)


@app.get("/api/rag/resources", response_model=RAGResourcesResponse)
async def rag_resources(request: Annotated[RAGResourceRequest, Query()]):
    """Get the resources of the RAG."""
    retriever = build_retriever()
    if retriever:
        return RAGResourcesResponse(resources=retriever.list_resources(request.query))
    return RAGResourcesResponse(resources=[])


@app.get("/api/config", response_model=ConfigResponse)
async def config():
    """Get the config of the server."""
    return ConfigResponse(
        rag=RAGConfigResponse(provider=SELECTED_RAG_PROVIDER),
        models=get_configured_llm_models(),
    )


@app.get("/api/chat/replay")
async def chat_replay(
    thread_id: Annotated[str, Query(description="Thread ID to replay")],
    offset: Annotated[str, Query(description="Offset to start reading from")] = "0",
    continuous: Annotated[bool, Query(description="Continuous mode: keep reading new events")] = False,
    query_id: Annotated[Optional[str], Query(description="Query ID, if not provided will find latest")] = None,
):
    """
    ä»Redis Streamå›æ”¾å¯¹è¯äº‹ä»¶
    
    Args:
        thread_id: çº¿ç¨‹ID
        offset: å¼€å§‹è¯»å–çš„ä½ç½®ï¼Œé»˜è®¤ä»å¤´å¼€å§‹
        continuous: è¿ç»­æ¨¡å¼ï¼Œæ˜¯å¦åœ¨è¯»å–å®Œç°æœ‰äº‹ä»¶åç»§ç»­ç­‰å¾…æ–°äº‹ä»¶
        query_id: æŸ¥è¯¢IDï¼Œå¦‚æœä¸æä¾›å°†è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„
    
    Returns:
        SSEæ ¼å¼çš„äº‹ä»¶æµ
    """
    
    async def replay_generator():
        try:
            import asyncio
            from src.async_tasks.task_manager import TaskManager
            
            # å¦‚æœæ²¡æœ‰æä¾›query_idæˆ–ä½¿ç”¨é»˜è®¤å€¼ï¼Œå°è¯•æŸ¥æ‰¾æœ€æ–°çš„
            target_query_id = query_id
            logger.info(f"ğŸ”§ query_idå‚æ•°: '{query_id}', ç±»å‹: {type(query_id)}")
            if not target_query_id or target_query_id == "default":
                logger.info(f"ğŸ” éœ€è¦æŸ¥æ‰¾æœ€æ–°query_id: thread_id={thread_id}")
                # æŸ¥æ‰¾è¯¥çº¿ç¨‹çš„æœ€æ–°æŸ¥è¯¢ID
                target_query_id = await find_latest_query_id(thread_id)
                logger.info(f"ğŸ¯ find_latest_query_idè¿”å›: '{target_query_id}'")
                if not target_query_id:
                    logger.warning(f"æœªæ‰¾åˆ°thread_id={thread_id}çš„æŸ¥è¯¢è®°å½•")
                    yield f"event: error\ndata: {json.dumps({'thread_id': thread_id, 'error': 'No query found for this thread'}, ensure_ascii=False)}\n\n"
                    return
            else:
                logger.info(f"ğŸ¯ ç›´æ¥ä½¿ç”¨æä¾›çš„query_id: '{target_query_id}'")
            
            logger.info(f"å¼€å§‹å›æ”¾å¯¹è¯: thread_id={thread_id}, query_id={target_query_id}, offset={offset}, continuous={continuous}")
            
            current_start = offset
            events_count = 0
            
            # è°ƒè¯•ï¼šè¾“å‡ºé‡è¦ä¿¡æ¯
            logger.info(f"ğŸ“Š å›æ”¾å‚æ•°: thread_id={thread_id}, target_query_id={target_query_id}, current_start={current_start}")
            
            # å…ˆè¯»å–æ‰€æœ‰ç°æœ‰çš„å†å²äº‹ä»¶
            while True:
                # ä»Redis Streamè¯»å–äº‹ä»¶ï¼ˆæ¯æ¬¡è¯»å–100ä¸ªï¼‰
                logger.info(f"ğŸ” å°è¯•ä»Redisè¯»å–äº‹ä»¶: thread_id={thread_id}, start={current_start}, stream_suffix={target_query_id}")
                events = read_events_from_stream(thread_id, start=current_start, stream_suffix=target_query_id, count=100)
                logger.info(f"ğŸ“– Redisè¯»å–ç»“æœ: è·å¾— {len(events)} ä¸ªäº‹ä»¶")
                
                if not events:
                    # æ²¡æœ‰æ›´å¤šå†å²äº‹ä»¶äº†
                    logger.info("â„¹ï¸ æ²¡æœ‰æ‰¾åˆ°æ›´å¤šäº‹ä»¶")
                    if not continuous:
                        # éè¿ç»­æ¨¡å¼ï¼šç›´æ¥ç»“æŸ
                        logger.info("ğŸ“´ éè¿ç»­æ¨¡å¼ï¼Œç»“æŸå›æ”¾")
                        break
                    else:
                        # è¿ç»­æ¨¡å¼ï¼šæ£€æŸ¥æ˜¯å¦æœ‰è¿è¡Œä¸­ä»»åŠ¡
                        task_mgr = TaskManager()
                        running_task = task_mgr.get_running_task_by_thread(thread_id)
                        if not running_task:
                            # æ²¡æœ‰è¿è¡Œä¸­ä»»åŠ¡ï¼Œç»“æŸ
                            logger.info("ğŸ“´ è¿ç»­æ¨¡å¼ä½†æ— è¿è¡Œä¸­ä»»åŠ¡ï¼Œç»“æŸå›æ”¾")
                            break
                        
                        # æœ‰è¿è¡Œä¸­ä»»åŠ¡ï¼Œç­‰å¾…1ç§’åç»§ç»­æ£€æŸ¥æ–°äº‹ä»¶
                        logger.info("â° è¿ç»­æ¨¡å¼ç­‰å¾…æ–°äº‹ä»¶...")
                        await asyncio.sleep(1)
                        continue
                
                # å¤„ç†è¯»å–åˆ°çš„äº‹ä»¶
                for i, event in enumerate(events):
                    try:
                        # é‡æ„äº‹ä»¶æ•°æ®ä¸ºå‰ç«¯æœŸæœ›çš„æ ¼å¼
                        event_type = event.get("event", "unknown")
                        event_data = event.get("data", {})
                        
                        logger.debug(f"ğŸ¬ å¤„ç†äº‹ä»¶ {i+1}: type={event_type}, data_keys={list(event_data.keys())}")
                        
                        # ç¡®ä¿thread_idåœ¨æ•°æ®ä¸­
                        if "thread_id" not in event_data:
                            event_data["thread_id"] = thread_id
                        
                        # ç”ŸæˆSSEæ ¼å¼çš„äº‹ä»¶
                        sse_event = f"event: {event_type}\ndata: {json.dumps(event_data, ensure_ascii=False)}\n\n"
                        yield sse_event
                        
                        # æ›´æ–°ä¸‹æ¬¡è¯»å–çš„èµ·å§‹ä½ç½®ï¼ˆä½¿ç”¨ä¸‹ä¸€ä¸ªIDé¿å…é‡å¤è¯»å–ï¼‰
                        event_id = event.get("id")
                        if event_id:
                            current_start = get_next_stream_id(event_id)
                        
                        events_count += 1
                        
                        logger.debug(f"âœ… å·²å‘é€äº‹ä»¶: {event_type}, ID: {event_id}, ä¸‹æ¬¡èµ·å§‹: {current_start}")
                        
                    except Exception as e:
                        logger.error(f"âŒ å¤„ç†å›æ”¾äº‹ä»¶æ—¶å‡ºé”™: {e}, äº‹ä»¶: {event}")
                        continue
                
                # å¦‚æœè¿™æ‰¹äº‹ä»¶æ•°é‡å°‘äº100ï¼Œè¯´æ˜å·²ç»è¯»å–å®Œæ‰€æœ‰å†å²äº‹ä»¶
                if len(events) < 100:
                    if not continuous:
                        logger.info("ğŸ“‹ å†å²äº‹ä»¶è¯»å–å®Œæ¯•ï¼Œéè¿ç»­æ¨¡å¼ç»“æŸ")
                        break
                    
                    # è¿ç»­æ¨¡å¼ï¼šç»§ç»­å¾ªç¯ç­‰å¾…æ–°äº‹ä»¶
                    logger.info("ğŸ“‹ å†å²äº‹ä»¶è¯»å–å®Œæ¯•ï¼Œè¿ç»­æ¨¡å¼ç»§ç»­ç­‰å¾…...")
                    # current_start å·²ç»æ›´æ–°ä¸ºæœ€åäº‹ä»¶çš„ä¸‹ä¸€ä¸ªIDï¼Œç»§ç»­ä½¿ç”¨å³å¯
            
            # å‘é€ç»“æŸæ ‡è®°
            mode = "continuous" if continuous else "static"
            yield f"event: replay_end\ndata: {json.dumps({'thread_id': thread_id, 'query_id': target_query_id, 'mode': mode, 'total_events': events_count}, ensure_ascii=False)}\n\n"
            logger.info(f"å›æ”¾å®Œæˆ: thread_id={thread_id}, query_id={target_query_id}, æ¨¡å¼={mode}, å…±å›æ”¾ {events_count} ä¸ªäº‹ä»¶")
            
        except Exception as e:
            logger.error(f"å›æ”¾è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            error_event = {
                "thread_id": thread_id,
                "error": str(e),
                "message": "å›æ”¾è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯"
            }
            yield f"event: error\ndata: {json.dumps(error_event, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        replay_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
        }
    )


# ==================== å¼‚æ­¥ä»»åŠ¡ API ====================

@app.get("/api/threads/{thread_id}/running-task")
async def get_thread_running_task(thread_id: str):
    """
    æ£€æŸ¥çº¿ç¨‹æ˜¯å¦æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡
    
    Args:
        thread_id: çº¿ç¨‹ID
        
    Returns:
        dict: è¿è¡Œä»»åŠ¡ä¿¡æ¯æˆ–None
    """
    try:
        running_task = task_manager.get_running_task_by_thread(thread_id)
        
        if running_task:
            return {
                "has_running_task": True,
                "task_id": running_task.task_id,
                "status": running_task.status.value,
                "progress": running_task.progress,
                "current_step": running_task.current_step,
                "started_at": running_task.started_at.isoformat() if running_task.started_at else None
            }
        else:
            return {
                "has_running_task": False,
                "task_id": None
            }
            
    except Exception as e:
        logger.error(f"æ£€æŸ¥çº¿ç¨‹è¿è¡Œä»»åŠ¡å¤±è´¥: thread_id={thread_id}, error={e}")
        raise HTTPException(status_code=500, detail=f"æ£€æŸ¥è¿è¡Œä»»åŠ¡å¤±è´¥: {str(e)}")

@app.post("/api/chat/start-async")
async def start_async_chat_task(request: ChatRequest):
    """
    åŸºäºChatRequestå¯åŠ¨å¼‚æ­¥ä»»åŠ¡ï¼ˆç®€åŒ–ç‰ˆAPIï¼‰
    
    Args:
        request: èŠå¤©è¯·æ±‚ï¼ˆå¤ç”¨ç°æœ‰æ ¼å¼ï¼‰
        
    Returns:
        dict: ä»»åŠ¡åˆ›å»ºå“åº”
    """
    try:
        logger.info(f"å¯åŠ¨å¼‚æ­¥èŠå¤©ä»»åŠ¡: thread_id={request.thread_id}")
        
        # æ„å»ºä»»åŠ¡é…ç½®
        task_config = {
            "messages": [msg.dict() for msg in request.messages] if request.messages else [],
            "resources": request.resources or [],
            "max_plan_iterations": request.max_plan_iterations,
            "max_step_num": request.max_step_num,
            "max_search_results": request.max_search_results,
            "auto_accepted_plan": request.auto_accepted_plan,
            "interrupt_feedback": request.interrupt_feedback,
            "mcp_settings": request.mcp_settings or {},
            "enable_background_investigation": request.enable_background_investigation,
            "report_style": request.report_style.value if request.report_style else "academic",
            "enable_deep_thinking": request.enable_deep_thinking,
        }
        
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = ""
        if request.messages:
            for msg in reversed(request.messages):
                if msg.role == "user" and msg.content:
                    if isinstance(msg.content, str):
                        user_input = msg.content
                    elif isinstance(msg.content, list):
                        # æå–æ–‡æœ¬å†…å®¹
                        for item in msg.content:
                            if isinstance(item, dict) and item.get("type") == "text":
                                user_input = item.get("text", "")
                                break
                    break
        
        # åˆ›å»ºä»»åŠ¡
        task_info = task_manager.create_task(
            thread_id=request.thread_id,
            user_input=user_input,
            config=task_config
        )
        
        # æäº¤ä»»åŠ¡åˆ°åå°å·¥ä½œå™¨
        success = background_worker.submit_task(task_info)
        if not success:
            raise HTTPException(status_code=500, detail="æäº¤ä»»åŠ¡åˆ°åå°å·¥ä½œå™¨å¤±è´¥")
        
        return {
            "task_id": task_info.task_id,
            "thread_id": task_info.thread_id,
            "status": task_info.status.value,
            "message": "å¼‚æ­¥èŠå¤©ä»»åŠ¡å·²åˆ›å»ºå¹¶å¼€å§‹æ‰§è¡Œ",
            "created_at": task_info.created_at.isoformat()
        }
        
    except Exception as e:
        logger.error(f"å¯åŠ¨å¼‚æ­¥èŠå¤©ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨å¼‚æ­¥ä»»åŠ¡å¤±è´¥: {str(e)}")

@app.post("/api/chat/async", response_model=AsyncTaskResponse)
async def create_async_task(request: AsyncTaskRequest):
    """
    åˆ›å»ºå¼‚æ­¥ä»»åŠ¡ï¼ˆå†…ç½®æ‰§è¡Œï¼Œæ— éœ€åå°å·¥ä½œå™¨ï¼‰
    
    Args:
        request: å¼‚æ­¥ä»»åŠ¡è¯·æ±‚
        
    Returns:
        AsyncTaskResponse: ä»»åŠ¡åˆ›å»ºå“åº”
    """
    try:
        logger.info(f"åˆ›å»ºå¼‚æ­¥ä»»åŠ¡: thread_id={request.thread_id}")
        
        # è·å–ç”¨æˆ·è¾“å…¥
        user_input = ""
        if request.messages:
            for msg in reversed(request.messages):
                if msg.get("role") == "user" and msg.get("content"):
                    user_input = msg["content"]
                    break
        
        # åˆ›å»ºä»»åŠ¡è®°å½•
        task_info = task_manager.create_task(
            thread_id=request.thread_id,
            user_input=user_input,
            config={
                "messages": request.messages or [],
                "resources": request.resources or [],
                "max_plan_iterations": request.max_plan_iterations,
                "max_step_num": request.max_step_num,
                "max_search_results": request.max_search_results,
                "auto_accepted_plan": request.auto_accepted_plan,
                "interrupt_feedback": request.interrupt_feedback,
                "mcp_settings": request.mcp_settings or {},
                "enable_background_investigation": request.enable_background_investigation,
                "report_style": request.report_style.value if request.report_style else "academic",
                "enable_deep_thinking": request.enable_deep_thinking,
            }
        )
        
        # ç›´æ¥åœ¨å½“å‰è¿›ç¨‹ä¸­å¼‚æ­¥æ‰§è¡Œä»»åŠ¡
        async def execute_async_task():
            """å¼‚æ­¥æ‰§è¡Œä»»åŠ¡çš„å†…éƒ¨å‡½æ•°"""
            try:
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºè¿è¡Œä¸­
                task_manager.update_task_status(task_info.task_id, TaskStatus.RUNNING)
                
                # å¯¼å…¥å¿…è¦çš„æ¨¡å—
                from src.async_tasks.stream_runner import StreamGraphRunner
                
                # åˆ›å»ºStreamGraphRunnerå¹¶æ‰§è¡Œ
                runner = StreamGraphRunner()
                
                # æ‰§è¡Œå·¥ä½œæµ
                result = await runner.execute_async(
                    task_id=task_info.task_id,
                    messages=task_info.config.get("messages", []),
                    thread_id=task_info.thread_id,
                    resources=task_info.config.get("resources", []),
                    max_plan_iterations=task_info.config.get("max_plan_iterations", 1),
                    max_step_num=task_info.config.get("max_step_num", 3),
                    max_search_results=task_info.config.get("max_search_results", 10),
                    auto_accepted_plan=task_info.config.get("auto_accepted_plan", True),
                    interrupt_feedback=task_info.config.get("interrupt_feedback", ""),
                    mcp_settings=task_info.config.get("mcp_settings", {}),
                    enable_background_investigation=task_info.config.get("enable_background_investigation", True),
                    report_style=ReportStyle(task_info.config.get("report_style", "academic")),
                    enable_deep_thinking=task_info.config.get("enable_deep_thinking", False)
                )
                
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
                task_manager.update_task_status(task_info.task_id, TaskStatus.COMPLETED)
                logger.info(f"å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œå®Œæˆ: task_id={task_info.task_id}")
                
            except Exception as e:
                logger.error(f"å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥: task_id={task_info.task_id}, error={e}")
                task_manager.update_task_status(task_info.task_id, TaskStatus.FAILED, error_message=str(e))
        
        # åˆ›å»ºåå°ä»»åŠ¡
        asyncio.create_task(execute_async_task())
        
        return AsyncTaskResponse(
            task_id=task_info.task_id,
            thread_id=task_info.thread_id,
            status=task_info.status.value,
            message="å¼‚æ­¥ä»»åŠ¡å·²åˆ›å»ºå¹¶å¼€å§‹æ‰§è¡Œ",
            created_at=task_info.created_at.isoformat()
        )
        
    except Exception as e:
        logger.error(f"åˆ›å»ºå¼‚æ­¥ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºå¼‚æ­¥ä»»åŠ¡å¤±è´¥: {str(e)}")


@app.get("/api/tasks/{task_id}", response_model=TaskStatusResponse)
async def get_task_status(task_id: str):
    """
    è·å–ä»»åŠ¡çŠ¶æ€
    
    Args:
        task_id: ä»»åŠ¡ID
        
    Returns:
        TaskStatusResponse: ä»»åŠ¡çŠ¶æ€å“åº”
    """
    try:
        # ç›´æ¥ä»TaskManagerè·å–ä»»åŠ¡çŠ¶æ€
        task_info = task_manager.get_task(task_id)
        
        if not task_info:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        task_dict = task_info.to_dict()
        return TaskStatusResponse(**task_dict)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: task_id={task_id}, error={e}")
        raise HTTPException(status_code=500, detail=f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")


@app.get("/api/tasks", response_model=TaskListResponse)
async def list_tasks(
    thread_id: Optional[str] = Query(None, description="çº¿ç¨‹IDè¿‡æ»¤"),
    status: Optional[str] = Query(None, description="çŠ¶æ€è¿‡æ»¤"),
    limit: int = Query(20, description="è¿”å›æ•°é‡é™åˆ¶", ge=1, le=100)
):
    """
    è·å–ä»»åŠ¡åˆ—è¡¨
    
    Args:
        thread_id: å¯é€‰çš„çº¿ç¨‹IDè¿‡æ»¤
        status: å¯é€‰çš„çŠ¶æ€è¿‡æ»¤
        limit: è¿”å›æ•°é‡é™åˆ¶
        
    Returns:
        TaskListResponse: ä»»åŠ¡åˆ—è¡¨å“åº”
    """
    try:
        if thread_id:
            # è·å–ç‰¹å®šçº¿ç¨‹çš„ä»»åŠ¡
            tasks = task_manager.get_tasks_by_thread(thread_id)
        else:
            # è·å–æ‰€æœ‰ä»»åŠ¡ï¼ˆè¿™é‡Œç®€åŒ–å®ç°ï¼Œå®é™…å¯èƒ½éœ€è¦åˆ†é¡µï¼‰
            task_ids = task_manager.redis_client.lrange(
                task_manager.task_list_key, 0, limit - 1
            )
            tasks = []
            for task_id in task_ids:
                task_info = task_manager.get_task(task_id)
                if task_info:
                    tasks.append(task_info)
        
        # çŠ¶æ€è¿‡æ»¤
        if status:
            tasks = [t for t in tasks if t.status.value == status]
        
        # é™åˆ¶æ•°é‡
        tasks = tasks[:limit]
        
        # è½¬æ¢ä¸ºå“åº”æ ¼å¼
        task_responses = []
        for task_info in tasks:
            task_dict = task_info.to_dict()
            task_responses.append(TaskStatusResponse(**task_dict))
        
        return TaskListResponse(
            tasks=task_responses,
            total_count=len(task_responses)
        )
        
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {str(e)}")


@app.post("/api/tasks/{task_id}/cancel", response_model=TaskCancelResponse)
async def cancel_task(task_id: str):
    """
    å–æ¶ˆä»»åŠ¡
    
    Args:
        task_id: ä»»åŠ¡ID
        
    Returns:
        TaskCancelResponse: å–æ¶ˆå“åº”
    """
    try:
        # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å­˜åœ¨
        task_info = task_manager.get_task(task_id)
        if not task_info:
            return TaskCancelResponse(
                task_id=task_id,
                success=False,
                message="ä»»åŠ¡ä¸å­˜åœ¨"
            )
        
        # å¦‚æœä»»åŠ¡è¿˜åœ¨è¿è¡Œï¼Œåˆ™æ›´æ–°çŠ¶æ€ä¸ºå–æ¶ˆ
        if task_info.status.value in ["pending", "running"]:
            task_manager.update_task_status(task_id, TaskStatus.CANCELLED)
            return TaskCancelResponse(
                task_id=task_id,
                success=True,
                message="ä»»åŠ¡å·²æˆåŠŸå–æ¶ˆ"
            )
        else:
            return TaskCancelResponse(
                task_id=task_id,
                success=False,
                message="ä»»åŠ¡å·²å®Œæˆæˆ–å·²å–æ¶ˆï¼Œæ— æ³•å–æ¶ˆ"
            )
            
    except Exception as e:
        logger.error(f"å–æ¶ˆä»»åŠ¡å¤±è´¥: task_id={task_id}, error={e}")
        raise HTTPException(status_code=500, detail=f"å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}")


@app.get("/api/worker/stats", response_model=WorkerStatsResponse)
async def get_worker_stats():
    """
    è·å–å·¥ä½œå™¨çŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œæ— éœ€åå°å·¥ä½œå™¨ï¼‰
    
    Returns:
        WorkerStatsResponse: å·¥ä½œå™¨çŠ¶æ€å“åº”
    """
    try:
        # ç®€åŒ–çš„ç»Ÿè®¡ä¿¡æ¯ï¼ŒåŸºäºTaskManager
        total_tasks = len(task_manager.redis_client.lrange(task_manager.task_list_key, 0, -1))
        
        # ç»Ÿè®¡å„ç§çŠ¶æ€çš„ä»»åŠ¡æ•°é‡
        pending_count = 0
        running_count = 0
        completed_count = 0
        failed_count = 0
        
        task_ids = task_manager.redis_client.lrange(task_manager.task_list_key, 0, -1)
        for task_id in task_ids[:100]:  # é™åˆ¶æ£€æŸ¥æ•°é‡é¿å…æ€§èƒ½é—®é¢˜
            task_info = task_manager.get_task(task_id)
            if task_info:
                if task_info.status.value == "pending":
                    pending_count += 1
                elif task_info.status.value == "running":
                    running_count += 1
                elif task_info.status.value == "completed":
                    completed_count += 1
                elif task_info.status.value == "failed":
                    failed_count += 1
        
        stats = {
            "is_running": True,  # APIæœåŠ¡å™¨æœ¬èº«åœ¨è¿è¡Œ
            "total_tasks": total_tasks,
            "pending_tasks": pending_count,
            "running_tasks": running_count,
            "completed_tasks": completed_count,
            "failed_tasks": failed_count,
            "max_concurrent_tasks": 10,  # ç†è®ºä¸Šçš„å¼‚æ­¥ä»»åŠ¡å¹¶å‘æ•°
            "uptime_seconds": 0  # æš‚æ—¶ä¸è®¡ç®—
        }
        
        return WorkerStatsResponse(**stats)
        
    except Exception as e:
        logger.error(f"è·å–å·¥ä½œå™¨çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œå™¨çŠ¶æ€å¤±è´¥: {str(e)}")


@app.post("/api/worker/cleanup")
async def cleanup_old_tasks(days: int = Query(7, description="æ¸…ç†å¤©æ•°", ge=1, le=30)):
    """
    æ¸…ç†è¿‡æœŸä»»åŠ¡
    
    Args:
        days: æ¸…ç†å‡ å¤©å‰çš„ä»»åŠ¡
        
    Returns:
        dict: æ¸…ç†ç»“æœ
    """
    try:
        cleaned_count = task_manager.cleanup_old_tasks(days)
        
        return {
            "success": True,
            "message": f"æˆåŠŸæ¸…ç† {cleaned_count} ä¸ªè¿‡æœŸä»»åŠ¡",
            "cleaned_count": cleaned_count,
            "retention_days": days
        }
        
    except Exception as e:
        logger.error(f"æ¸…ç†è¿‡æœŸä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†è¿‡æœŸä»»åŠ¡å¤±è´¥: {str(e)}")


async def find_latest_query_id(thread_id: str) -> Optional[str]:
    """
    æŸ¥æ‰¾æŒ‡å®šçº¿ç¨‹çš„æœ€æ–°æŸ¥è¯¢ID
    
    Args:
        thread_id: çº¿ç¨‹ID
        
    Returns:
        str: æœ€æ–°çš„æŸ¥è¯¢IDï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°è¿”å›None
    """
    try:
        from src.config.redis_config import get_redis_client
        redis_client = get_redis_client()
        
        # æœç´¢æ‰€æœ‰ç›¸å…³çš„stream keys
        pattern = f"chat:{thread_id}:*"
        keys = redis_client.keys(pattern)
        
        if not keys:
            logger.info(f"ğŸ” find_latest_query_id: æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„é”® pattern={pattern}")
            return None
        
        # æå–query_idå¹¶æ‰¾åˆ°æœ€æ–°çš„ï¼ˆåŸºäºæ—¶é—´æˆ³ï¼‰
        latest_query_id = None
        latest_timestamp = 0
        
        for key in keys:
            # keyæ ¼å¼: chat:{thread_id}:{query_id}
            key_str = key.decode('utf-8') if isinstance(key, bytes) else key
            parts = key_str.split(':')
            if len(parts) >= 3:
                query_id = ':'.join(parts[2:])  # æ”¯æŒquery_idä¸­åŒ…å«å†’å·
                
                # è·å–streamçš„æœ€æ–°äº‹ä»¶æ¥åˆ¤æ–­æ—¶é—´
                try:
                    # è·å–è¯¥streamçš„æœ€åä¸€ä¸ªäº‹ä»¶
                    last_events = redis_client.xrevrange(key_str, count=1)
                    if last_events:
                        event_id = last_events[0][0]
                        # Redis stream IDæ ¼å¼: timestamp-sequence
                        timestamp = int(event_id.decode('utf-8').split('-')[0])
                        if timestamp > latest_timestamp:
                            latest_timestamp = timestamp
                            latest_query_id = query_id
                except Exception as e:
                    logger.warning(f"å¤„ç†stream key {key_str} æ—¶å‡ºé”™: {e}")
                    continue
        
        logger.info(f"ğŸ¯ find_latest_query_idç»“æœ: thread_id={thread_id}, latest_query_id={latest_query_id}")
        return latest_query_id
        
    except Exception as e:
        logger.error(f"find_latest_query_idå‡ºé”™: {e}")
        return None


def get_next_stream_id(current_id: str) -> str:
    """
    è·å–ä¸‹ä¸€ä¸ªStream IDï¼Œç”¨äºé¿å…é‡å¤è¯»å–åŒä¸€ä¸ªäº‹ä»¶
    
    Args:
        current_id: å½“å‰äº‹ä»¶IDï¼Œæ ¼å¼ä¸º "timestamp-sequence"
        
    Returns:
        str: ä¸‹ä¸€ä¸ªID
    """
    try:
        if current_id == "0":
            return "0"
        
        # è§£æå½“å‰ID
        parts = current_id.split('-')
        if len(parts) != 2:
            return current_id
        
        timestamp = int(parts[0])
        sequence = int(parts[1])
        
        # è¿”å›ä¸‹ä¸€ä¸ªsequence
        return f"{timestamp}-{sequence + 1}"
    except:
        # å¦‚æœè§£æå¤±è´¥ï¼Œç›´æ¥è¿”å›åŸID
        return current_id


def should_save_tool_call_chunk(chunk) -> bool:
    """åˆ¤æ–­tool_call_chunkæ˜¯å¦å€¼å¾—ä¿å­˜åˆ°Redis Stream"""
    try:
        args = chunk.get('args', '')
        
        # ç©ºå†…å®¹ä¸ä¿å­˜
        if not args or args is None:
            return False
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¤„ç†
        args_str = str(args).strip()
        
        # ç©ºå­—ç¬¦ä¸²ä¸ä¿å­˜
        if not args_str:
            return False
        
        # åªæœ‰å•ä¸ªå­—ç¬¦çš„æ— æ„ä¹‰ç‰‡æ®µä¸ä¿å­˜ï¼ˆå¦‚ "2", "%", "www", "{", "}"ç­‰ï¼‰
        if len(args_str) <= 2:
            # ä½†æ˜¯ä¿ç•™æœ‰æ„ä¹‰çš„çŸ­å­—ç¬¦ä¸²ï¼Œå¦‚ ": ", ", ", ":\""ç­‰
            meaningful_shorts = [': ', ', ', '": ', '" ', '": "', '", "', '}', '];']
            if args_str not in meaningful_shorts:
                return False
        
        # è¿‡æ»¤æ‰ä¸€äº›æ˜æ˜¾æ— ç”¨çš„å•å­—ç¬¦æˆ–çŸ­ç‰‡æ®µ
        useless_patterns = ['2', '%', 'www', '#', '.', '/', '\\n', '=', ' =', 'ï¼‰\\n', '10', ' æ–‡', 'è´¹ç”¨', 'ä¸è¶…è¿‡', 'ç±»ä¼¼', 'é™', '80', 'ï¼š', '8', '.s']
        if args_str in useless_patterns:
            return False
        
        return True
        
    except Exception as e:
        logger.warning(f"åˆ¤æ–­tool_call_chunkæœ‰æ•ˆæ€§å¤±è´¥: {e}, chunk: {chunk}")
        # å‡ºé”™æ—¶é»˜è®¤ä¿å­˜ï¼Œé¿å…ä¸¢å¤±é‡è¦æ•°æ®
        return True


@app.get("/api/threads/{thread_id}/research-status")
async def get_thread_research_status(thread_id: str):
    """
    æ£€æŸ¥æŒ‡å®šçº¿ç¨‹æ˜¯å¦æœ‰ç ”ç©¶äº‹ä»¶
    
    Returns:
        - has_research_events: æ˜¯å¦æœ‰ç ”ç©¶ç›¸å…³äº‹ä»¶
        - ongoing_research: æ­£åœ¨è¿›è¡Œçš„ç ”ç©¶ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        - completed_research: å·²å®Œæˆçš„ç ”ç©¶åˆ—è¡¨
        - latest_research_id: æœ€æ–°çš„ç ”ç©¶ID
    """
    try:
        logger.info(f"ğŸ” æ£€æŸ¥çº¿ç¨‹ {thread_id} çš„ç ”ç©¶çŠ¶æ€")
        
        # 1. æ£€æŸ¥æ˜¯å¦æœ‰è¿è¡Œä¸­çš„ä»»åŠ¡
        running_task_info = await get_thread_running_task(thread_id)
        
        # 2. æœç´¢Redis Streamä¸­çš„ç ”ç©¶äº‹ä»¶
        from src.config.redis_config import get_redis_client
        client = get_redis_client()
        
        # æœç´¢è¯¥çº¿ç¨‹çš„æ‰€æœ‰stream keys
        pattern = f"chat:{thread_id}:*"
        stream_keys = client.keys(pattern)
        
        research_events = {
            "has_research_events": False,
            "ongoing_research": None,
            "completed_research": [],
            "latest_research_id": None,
            "running_task": running_task_info
        }
        
        if not stream_keys:
            logger.info(f"ğŸ“­ çº¿ç¨‹ {thread_id} æ²¡æœ‰æ‰¾åˆ°ä»»ä½•stream keys")
            return research_events
        
        logger.info(f"ğŸ”‘ çº¿ç¨‹ {thread_id} æ‰¾åˆ° {len(stream_keys)} ä¸ªstream keys: {stream_keys}")
        
        # 3. æ‰«ææ¯ä¸ªstreamï¼ŒæŸ¥æ‰¾ç ”ç©¶ç›¸å…³äº‹ä»¶
        all_research_events = []
        
        for stream_key in stream_keys:
            try:
                # è¯»å–è¯¥streamçš„æ‰€æœ‰äº‹ä»¶ï¼ˆé™åˆ¶æ•°é‡é¿å…å¤ªè€—æ—¶ï¼‰
                messages = client.xrange(stream_key, count=200)
                
                for message_id, fields in messages:
                    event_type = fields.get("event")
                    
                    if event_type in ["research_start", "research_end"]:
                        try:
                            import json
                            data_json = fields.get("data_json", "{}")
                            event_data = json.loads(data_json)
                            
                            all_research_events.append({
                                "stream_key": stream_key,
                                "message_id": message_id,
                                "event_type": event_type,
                                "event_data": event_data,
                                "timestamp": message_id  # Redis stream IDå¯ä»¥ä½œä¸ºæ—¶é—´æˆ³
                            })
                            
                            logger.debug(f"ğŸ“Š å‘ç°ç ”ç©¶äº‹ä»¶: {event_type}, stream={stream_key}, data={event_data}")
                            
                        except json.JSONDecodeError as e:
                            logger.warning(f"âš ï¸ è§£æäº‹ä»¶æ•°æ®å¤±è´¥: {e}")
                            continue
                            
            except Exception as e:
                logger.warning(f"âš ï¸ è¯»å–streamå¤±è´¥ {stream_key}: {e}")
                continue
        
        if not all_research_events:
            logger.info(f"ğŸ“­ çº¿ç¨‹ {thread_id} æ²¡æœ‰æ‰¾åˆ°ç ”ç©¶äº‹ä»¶")
            return research_events
        
        # 4. åˆ†æç ”ç©¶äº‹ä»¶ï¼Œæ„å»ºçŠ¶æ€
        research_events["has_research_events"] = True
        
        # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆRedis stream IDæ˜¯é€’å¢çš„ï¼‰
        all_research_events.sort(key=lambda x: x["timestamp"])
        
        # è·Ÿè¸ªæ¯ä¸ªç ”ç©¶çš„çŠ¶æ€
        research_status = {}  # research_id -> latest_status
        
        for event in all_research_events:
            event_type = event["event_type"]
            event_data = event["event_data"]
            research_id = event_data.get("research_id") or event_data.get("id")
            
            if not research_id:
                continue
                
            if event_type == "research_start":
                research_status[research_id] = {
                    "research_id": research_id,
                    "status": "running",
                    "topic": event_data.get("topic", ""),
                    "query_id": event_data.get("query_id", ""),
                    "start_time": event["timestamp"],
                    "stream_key": event["stream_key"]
                }
            elif event_type == "research_end":
                if research_id in research_status:
                    research_status[research_id]["status"] = "completed"
                    research_status[research_id]["end_time"] = event["timestamp"]
                else:
                    # å¯èƒ½åªæœ‰endäº‹ä»¶ï¼Œåˆ›å»ºä¸€ä¸ªcompletedçŠ¶æ€çš„è®°å½•
                    research_status[research_id] = {
                        "research_id": research_id,
                        "status": "completed",
                        "topic": event_data.get("topic", ""),
                        "query_id": event_data.get("query_id", ""),
                        "end_time": event["timestamp"],
                        "stream_key": event["stream_key"]
                    }
        
        # 5. åˆ†ç±»ç ”ç©¶çŠ¶æ€
        ongoing_research = None
        completed_research = []
        latest_research_id = None
        
        for research_id, status in research_status.items():
            if status["status"] == "running":
                ongoing_research = status
            elif status["status"] == "completed":
                completed_research.append(status)
            
            # æ›´æ–°æœ€æ–°çš„ç ”ç©¶IDï¼ˆæŒ‰æ—¶é—´æˆ³ï¼‰
            if latest_research_id is None:
                latest_research_id = research_id
            else:
                current_latest = research_status[latest_research_id]
                latest_time = current_latest.get("end_time") or current_latest.get("start_time")
                this_time = status.get("end_time") or status.get("start_time")
                if this_time > latest_time:
                    latest_research_id = research_id
        
        # æŒ‰æ—¶é—´å€’åºæ’åˆ—å·²å®Œæˆçš„ç ”ç©¶
        completed_research.sort(key=lambda x: x.get("end_time", x.get("start_time", "")), reverse=True)
        
        research_events.update({
            "ongoing_research": ongoing_research,
            "completed_research": completed_research,
            "latest_research_id": latest_research_id,
        })
        
        logger.info(f"âœ… çº¿ç¨‹ {thread_id} ç ”ç©¶çŠ¶æ€åˆ†æå®Œæˆ: ongoing={bool(ongoing_research)}, completed={len(completed_research)}, latest={latest_research_id}")
        
        return research_events
        
    except Exception as e:
        logger.error(f"âŒ æ£€æŸ¥çº¿ç¨‹ç ”ç©¶çŠ¶æ€å¤±è´¥ {thread_id}: {e}")
        import traceback
        logger.error(f"âŒ å †æ ˆè·Ÿè¸ª: {traceback.format_exc()}")
        return {
            "has_research_events": False,
            "ongoing_research": None,
            "completed_research": [],
            "latest_research_id": None,
            "running_task": None,
            "error": str(e)
        }
